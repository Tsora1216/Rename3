{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load & process the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416271, 366)\n"
     ]
    }
   ],
   "source": [
    "# Load the extracted features for Sleep-EDF-SC-78\n",
    "# Note: to extract the features run the notebook SleepEDF-SC +/- 30min.ipynb\n",
    "\n",
    "df_feats = pd.read_parquet(\"../../features/sleep-edf__cassette_features_ALL__90s.parquet\")\n",
    "print(df_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416271, 396)\n",
      "(416143, 396)\n",
      "(414813, 396)\n",
      "Sleep stage W    285286\n",
      "Sleep stage 2     69132\n",
      "Sleep stage R     25835\n",
      "Sleep stage 1     21521\n",
      "Sleep stage 3     13039\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Add some delta's & ratios to the features (just as in SleepEDF-SC +/- 30min.ipynb)\n",
    "\n",
    "sigs = list(set(c.split(\"__\")[0] for c in df_feats.columns))\n",
    "\n",
    "eeg_signals = [d for d in sigs if \"EEG\" in d]\n",
    "bands = [\"alpha\", \"beta\", \"sdelta\", \"fdelta\", \"sigma\", \"theta\"]\n",
    "for eeg_sig in eeg_signals:\n",
    "    eeg_bands = [c for c in df_feats.columns if c.startswith(eeg_sig) and c.split(\"__\")[1] in bands]\n",
    "    windows = sorted(set(b.split(\"__\")[-1] for b in eeg_bands))\n",
    "    for window in windows:\n",
    "        # Select the spectral powers\n",
    "        delta = df_feats[\"__\".join([eeg_sig, \"sdelta\", window])] + df_feats[\"__\".join([eeg_sig, \"fdelta\", window])]\n",
    "        fdelta_theta = df_feats[\"__\".join([eeg_sig, \"fdelta\", window])] + df_feats[\"__\".join([eeg_sig, \"theta\", window])]\n",
    "        alpha = df_feats[\"__\".join([eeg_sig, \"alpha\", window])]\n",
    "        beta = df_feats[\"__\".join([eeg_sig, \"beta\", window])]\n",
    "        theta = df_feats[\"__\".join([eeg_sig, \"theta\", window])]\n",
    "        sigma = df_feats[\"__\".join([eeg_sig, \"sigma\", window])]\n",
    "        # Calculate the ratios\n",
    "        df_feats[\"__\".join([eeg_sig, \"fdelta+theta\", window])] = fdelta_theta.astype(\"float32\")        \n",
    "\n",
    "        df_feats[\"__\".join([eeg_sig, \"alpha/theta\", window])] = (alpha / theta).astype(\"float32\")\n",
    "        df_feats[\"__\".join([eeg_sig, \"delta/beta\", window])] = (delta / beta).astype(\"float32\")\n",
    "        df_feats[\"__\".join([eeg_sig, \"delta/sigma\", window])] = (delta / sigma).astype(\"float32\")\n",
    "        df_feats[\"__\".join([eeg_sig, \"delta/theta\", window])] = (delta / theta).astype(\"float32\")\n",
    "\n",
    "print(df_feats.shape)\n",
    "\n",
    "df_feats = df_feats[df_feats.label != \"Movement time\"]\n",
    "print(df_feats.shape)\n",
    "df_feats = df_feats[df_feats.label != \"Sleep stage ?\"]\n",
    "print(df_feats.shape)\n",
    "df_feats[\"label\"] = df_feats.label.apply(lambda x: \"Sleep stage 3\" if x.endswith(\"4\") else x)\n",
    "print(df_feats.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 131 131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(414813, 1051)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform the temporal shifts (just as in SleepEDF-SC +/- 30min.ipynb)\n",
    "\n",
    "feats_30s = [f for f in df_feats.columns if \"w=30s\" in f]\n",
    "feats_60s = [f for f in df_feats.columns if \"w=1m_\" in f]\n",
    "feats_90s = [f for f in df_feats.columns if \"w=1m30s\" in f]\n",
    "print(len(feats_30s), len(feats_60s), len(feats_90s))\n",
    "dfs = []\n",
    "for psg_file in df_feats.psg_file.unique():\n",
    "    sub_df = df_feats[df_feats.psg_file == psg_file]\n",
    "\n",
    "    sub_df = sub_df.merge(\n",
    "        sub_df[feats_90s].shift(1).add_suffix(\"_shift=30s\"),\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "    sub_df = sub_df.drop(columns=feats_90s)\n",
    "\n",
    "    sub_df = sub_df.merge(\n",
    "        sub_df[feats_60s].shift(1).add_suffix(\"_shift=30s\"),\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    sub_df = sub_df.merge(sub_df[feats_30s].shift(2).add_suffix(\"_shift=1m\"), left_index=True, right_index=True)\n",
    "    sub_df = sub_df.merge(sub_df[feats_30s].shift(1).add_suffix(\"_shift=30s\"), left_index=True, right_index=True)\n",
    "    sub_df = sub_df.merge(sub_df[feats_30s].shift(-1).add_suffix(\"_shift=-30s\"), left_index=True, right_index=True)\n",
    "    sub_df = sub_df.merge(sub_df[feats_30s].shift(-2).add_suffix(\"_shift=-1m\"), left_index=True, right_index=True)\n",
    "    dfs += [sub_df]\n",
    "df_feats = pd.concat(dfs)\n",
    "df_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195168, 1051)\n"
     ]
    }
   ],
   "source": [
    "# Trim the features to include 30 min of wake time before/after sleep period\n",
    "\n",
    "def get_repeat_length(val, arr):\n",
    "    if arr[0] != val:\n",
    "        return 0\n",
    "    return np.where(arr != val)[0][0] + 1\n",
    "\n",
    "dfs = []\n",
    "for psg_file in df_feats[\"psg_file\"].unique():\n",
    "    sub_df = df_feats[df_feats.psg_file == psg_file]  # .sort_index()\n",
    "    labels = sub_df[\"label\"].values\n",
    "    nb_wake_before_sleep = get_repeat_length(\"Sleep stage W\", labels)\n",
    "    nb_wake_after_sleep = get_repeat_length(\"Sleep stage W\", labels[::-1])\n",
    "    start_idx = max(0, nb_wake_before_sleep - 30 * 2)\n",
    "    end_idx = min(-1, -nb_wake_after_sleep + 30 * 2)\n",
    "    dfs.append(sub_df[start_idx:end_idx])\n",
    "df_feats = pd.concat(dfs)\n",
    "\n",
    "print(df_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048\n"
     ]
    }
   ],
   "source": [
    "feat_cols = [c for c in df_feats.columns if c not in [\"label\", \"psg_file\", \"patient_id\"]]\n",
    "print(len(feat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The linear model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold, cross_validate\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"impute\", SimpleImputer()),\n",
    "        (\"scale\", QuantileTransformer(n_quantiles=100, subsample=200_000, random_state=0)),\n",
    "        (\n",
    "            \"linear_model\",\n",
    "            SGDClassifier(\n",
    "                loss=\"log\",\n",
    "                average=True,\n",
    "                class_weight=\"balanced\",\n",
    "                n_jobs=5,\n",
    "                random_state=0,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Univariate feature selection (filter methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector:  SelectFdr()  % selected features:  0.9857\n",
      "Selector:  SelectFpr()  % selected features:  0.9857\n",
      "Selector:  SelectFwe()  % selected features:  0.9857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFdr, SelectFpr, SelectFwe, SelectPercentile, f_classif\n",
    "\n",
    "selector_obj = [\n",
    "    SelectFdr(f_classif),\n",
    "    SelectFpr(f_classif),\n",
    "    SelectFwe(f_classif),\n",
    "]\n",
    "\n",
    "X = df_feats[feat_cols].values\n",
    "X = SimpleImputer().fit_transform(X)\n",
    "\n",
    "for selector in selector_obj:\n",
    "    selector.fit(X, df_feats[\"label\"])\n",
    "    print(\"Selector: \", selector, \" % selected features: \", round(np.sum(selector.get_support()) / X.shape[1], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these techniques throw away 1.5% of the features, which will have minimal impact on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "NO Feature selection\n",
      "(195168, 1048)\n",
      "10-FOLD: TRAIN\n",
      "  MACRO F1:           0.7948\n",
      "  Balanced accuracy:  0.8105\n",
      "  Accuracy:           0.8407\n",
      "  Log loss:           0.5406\n",
      "10-FOLD: TEST\n",
      "  MACRO F1:           0.7698\n",
      "  Balanced accuracy:  0.7853\n",
      "  Accuracy:           0.8209\n",
      "  Log loss:           0.6601\n",
      "----------------------------------------\n",
      "Feature selection\n",
      "(195168, 1033)\n",
      "10-FOLD: TRAIN\n",
      "  MACRO F1:           0.7948\n",
      "  Balanced accuracy:  0.8103\n",
      "  Accuracy:           0.8407\n",
      "  Log loss:           0.5407\n",
      "10-FOLD: TEST\n",
      "  MACRO F1:           0.7693\n",
      "  Balanced accuracy:  0.7847\n",
      "  Accuracy:           0.8205\n",
      "  Log loss:           0.6606\n"
     ]
    }
   ],
   "source": [
    "selector = selector_obj[0]\n",
    "X_selected = selector.transform(X)\n",
    "\n",
    "# Total of 10 folds\n",
    "gkfold = StratifiedGroupKFold(n_splits=10)\n",
    "\n",
    "print(\"----\" * 10)\n",
    "print(\"NO Feature selection\")\n",
    "print(X.shape)\n",
    "cv = gkfold.split(X, df_feats[\"label\"], groups=df_feats.patient_id)\n",
    "res = cross_validate(\n",
    "    pipe,\n",
    "    X,\n",
    "    df_feats[\"label\"],\n",
    "    scoring=[\"f1_macro\", \"balanced_accuracy\", \"accuracy\", \"neg_log_loss\"],\n",
    "    cv=cv,\n",
    "    n_jobs=25,\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")\n",
    "\n",
    "print(\"10-FOLD: TRAIN\")\n",
    "print(\"  MACRO F1:          \", round(np.mean(res[\"train_f1_macro\"]), 4))\n",
    "print(\"  Balanced accuracy: \", round(np.mean(res[\"train_balanced_accuracy\"]), 4))\n",
    "print(\"  Accuracy:          \", round(np.mean(res[\"train_accuracy\"]), 4))\n",
    "print(\"  Log loss:          \", round(np.mean(-1 * res[\"train_neg_log_loss\"]), 4))\n",
    "\n",
    "print(\"10-FOLD: TEST\")\n",
    "print(\"  MACRO F1:          \", round(np.mean(res[\"test_f1_macro\"]), 4))\n",
    "print(\"  Balanced accuracy: \", round(np.mean(res[\"test_balanced_accuracy\"]), 4))\n",
    "print(\"  Accuracy:          \", round(np.mean(res[\"test_accuracy\"]), 4))\n",
    "print(\"  Log loss:          \", round(np.mean(-1 * res[\"test_neg_log_loss\"]), 4))\n",
    "\n",
    "print(\"----\" * 10)\n",
    "print(\"Feature selection\")\n",
    "print(X_selected.shape)\n",
    "cv = gkfold.split(X_selected, df_feats[\"label\"], groups=df_feats.patient_id)\n",
    "res = cross_validate(\n",
    "    pipe,\n",
    "    X_selected,\n",
    "    df_feats[\"label\"],\n",
    "    scoring=[\"f1_macro\", \"balanced_accuracy\", \"accuracy\", \"neg_log_loss\"],\n",
    "    cv=cv,\n",
    "    n_jobs=25,\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")\n",
    "\n",
    "print(\"10-FOLD: TRAIN\")\n",
    "print(\"  MACRO F1:          \", round(np.mean(res[\"train_f1_macro\"]), 4))\n",
    "print(\"  Balanced accuracy: \", round(np.mean(res[\"train_balanced_accuracy\"]), 4))\n",
    "print(\"  Accuracy:          \", round(np.mean(res[\"train_accuracy\"]), 4))\n",
    "print(\"  Log loss:          \", round(np.mean(-1 * res[\"train_neg_log_loss\"]), 4))\n",
    "\n",
    "print(\"10-FOLD: TEST\")\n",
    "print(\"  MACRO F1:          \", round(np.mean(res[\"test_f1_macro\"]), 4))\n",
    "print(\"  Balanced accuracy: \", round(np.mean(res[\"test_balanced_accuracy\"]), 4))\n",
    "print(\"  Accuracy:          \", round(np.mean(res[\"test_accuracy\"]), 4))\n",
    "print(\"  Log loss:          \", round(np.mean(-1 * res[\"test_neg_log_loss\"]), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Wrapper based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../powershap/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [26:25<00:00, 158.57s/it]\n",
      "100%|██████████| 10/10 [26:18<00:00, 157.81s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PowerShap(model=<catboost.core.CatBoostClassifier object at 0x7fe189179f10>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from powershap import PowerShap\n",
    "\n",
    "X = df_feats[feat_cols].values\n",
    "X = SimpleImputer().fit_transform(X)\n",
    "\n",
    "selector = PowerShap()\n",
    "selector.fit(X, df_feats[\"label\"], n_jobs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% features selected 0.1403\n",
      "(195168, 147) (195168, 1048)\n"
     ]
    }
   ],
   "source": [
    "X_selected = selector.transform(X)\n",
    "print(\"% features selected\", round(X_selected.shape[1] / X.shape[1], 4))\n",
    "print(X_selected.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "NO Feature selection\n",
      "(195168, 1048)\n",
      "10-FOLD: TRAIN\n",
      "  MACRO F1:           0.7948\n",
      "  Balanced accuracy:  0.8105\n",
      "  Accuracy:           0.8407\n",
      "  Log loss:           0.5406\n",
      "10-FOLD: TEST\n",
      "  MACRO F1:           0.7698\n",
      "  Balanced accuracy:  0.7853\n",
      "  Accuracy:           0.8209\n",
      "  Log loss:           0.6601\n",
      "----------------------------------------\n",
      "Feature selection\n",
      "(195168, 147)\n",
      "10-FOLD: TRAIN\n",
      "  MACRO F1:           0.7767\n",
      "  Balanced accuracy:  0.7927\n",
      "  Accuracy:           0.8268\n",
      "  Log loss:           0.4645\n",
      "10-FOLD: TEST\n",
      "  MACRO F1:           0.759\n",
      "  Balanced accuracy:  0.7754\n",
      "  Accuracy:           0.8128\n",
      "  Log loss:           0.5103\n"
     ]
    }
   ],
   "source": [
    "# Total of 10 folds\n",
    "gkfold = StratifiedGroupKFold(n_splits=10)\n",
    "\n",
    "print(\"----\" * 10)\n",
    "print(\"NO Feature selection\")\n",
    "print(X.shape)\n",
    "cv = gkfold.split(X, df_feats[\"label\"], groups=df_feats.patient_id)\n",
    "res = cross_validate(\n",
    "    pipe,\n",
    "    X,\n",
    "    df_feats[\"label\"],\n",
    "    scoring=[\"f1_macro\", \"balanced_accuracy\", \"accuracy\", \"neg_log_loss\"],\n",
    "    cv=cv,\n",
    "    n_jobs=25,\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")\n",
    "\n",
    "print(\"10-FOLD: TRAIN\")\n",
    "print(\"  MACRO F1:          \", round(np.mean(res[\"train_f1_macro\"]), 4))\n",
    "print(\"  Balanced accuracy: \", round(np.mean(res[\"train_balanced_accuracy\"]), 4))\n",
    "print(\"  Accuracy:          \", round(np.mean(res[\"train_accuracy\"]), 4))\n",
    "print(\"  Log loss:          \", round(np.mean(-1 * res[\"train_neg_log_loss\"]), 4))\n",
    "\n",
    "print(\"10-FOLD: TEST\")\n",
    "print(\"  MACRO F1:          \", round(np.mean(res[\"test_f1_macro\"]), 4))\n",
    "print(\"  Balanced accuracy: \", round(np.mean(res[\"test_balanced_accuracy\"]), 4))\n",
    "print(\"  Accuracy:          \", round(np.mean(res[\"test_accuracy\"]), 4))\n",
    "print(\"  Log loss:          \", round(np.mean(-1 * res[\"test_neg_log_loss\"]), 4))\n",
    "\n",
    "print(\"----\" * 10)\n",
    "print(\"Feature selection\")\n",
    "print(X_selected.shape)\n",
    "cv = gkfold.split(X_selected, df_feats[\"label\"], groups=df_feats.patient_id)\n",
    "res = cross_validate(\n",
    "    pipe,\n",
    "    X_selected,\n",
    "    df_feats[\"label\"],\n",
    "    scoring=[\"f1_macro\", \"balanced_accuracy\", \"accuracy\", \"neg_log_loss\"],\n",
    "    cv=cv,\n",
    "    n_jobs=25,\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")\n",
    "\n",
    "print(\"10-FOLD: TRAIN\")\n",
    "print(\"  MACRO F1:          \", round(np.mean(res[\"train_f1_macro\"]), 4))\n",
    "print(\"  Balanced accuracy: \", round(np.mean(res[\"train_balanced_accuracy\"]), 4))\n",
    "print(\"  Accuracy:          \", round(np.mean(res[\"train_accuracy\"]), 4))\n",
    "print(\"  Log loss:          \", round(np.mean(-1 * res[\"train_neg_log_loss\"]), 4))\n",
    "\n",
    "print(\"10-FOLD: TEST\")\n",
    "print(\"  MACRO F1:          \", round(np.mean(res[\"test_f1_macro\"]), 4))\n",
    "print(\"  Balanced accuracy: \", round(np.mean(res[\"test_balanced_accuracy\"]), 4))\n",
    "print(\"  Accuracy:          \", round(np.mean(res[\"test_accuracy\"]), 4))\n",
    "print(\"  Log loss:          \", round(np.mean(-1 * res[\"test_neg_log_loss\"]), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we observe a net negative effect when applying feature selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('sleep_paper-4f-yQ0G1-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d26647b37146e95e347876078aedcf35f94a4ca9526dc634d27d5a71ed3e309"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
